{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ8sWMh1zUSG1X+pEaAC7V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jegovila/cursoVR/blob/main/Practica9%3A%20Descriptores/python/Pr%C3%A1ctica9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MX5tyzUyOlQw"
      },
      "outputs": [],
      "source": [
        "!wget -nc \"https://raw.githubusercontent.com/Jegovila/cursoVR/main/Practica9%3A%20Descriptores/python/I1.jpg\"\n",
        "!wget -nc \"https://raw.githubusercontent.com/Jegovila/cursoVR/main/Practica9%3A%20Descriptores/python/I2.jpg\"\n",
        "!wget -nc \"https://raw.githubusercontent.com/Jegovila/cursoVR/main/Practica9%3A%20Descriptores/python/I3.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "56czahgHPD37"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 1"
      ],
      "metadata": {
        "id": "iaNe5uCkjVoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "I1 = cv2.imread(\"I1.jpg\")\n",
        "I2 = cv2.imread(\"I2.jpg\")\n",
        "\n",
        "I1 = cv2.resize(I1, (0,0), fx=0.2, fy=0.2)\n",
        "I2 = cv2.resize(I2, (0,0), fx=0.2, fy=0.2)\n",
        "\n",
        "fig, prev = plt.subplots(1, 2, figsize=(10,7))\n",
        "fig.tight_layout()\n",
        "plt.clf()\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(cv2.cvtColor(I1, cv2.COLOR_BGR2RGB))\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(cv2.cvtColor(I2, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "ZgUGtn-yPFRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elegir el algoritmo descriptor"
      ],
      "metadata": {
        "id": "oni-jK-hQeE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "descriptor = cv2.SIFT_create()\n",
        "#descriptor = cv2.xfeatures2d.SURF_create()\n",
        "#descriptor = cv2.ORB_create()\n",
        "#descriptor = cv2.AKAZE_create()"
      ],
      "metadata": {
        "id": "SGxjlrfvQASu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraer puntos de interés y calcular sus vectores descriptores"
      ],
      "metadata": {
        "id": "9L0S8htQQfz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kpts1, desc1 = descriptor.detectAndCompute(I1, None)\n",
        "kpts2, desc2 = descriptor.detectAndCompute(I2, None)\n",
        "\n",
        "print(\"Keypoints en imagen 1: \", len(kpts1))\n",
        "print(desc1.shape[0], \" descriptores en imagen 1, de tamaño: \", desc1.shape[1])\n",
        "\n",
        "print(\"Keypoints en imagen 2: \", len(kpts2))\n",
        "print(desc2.shape[0], \" descriptores en imagen 2, de tamaño: \", desc2.shape[1])"
      ],
      "metadata": {
        "id": "XAnggKtfP8tJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hacer matches"
      ],
      "metadata": {
        "id": "exOhTCCaa3QN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
        "matches = bf.match(desc1, desc2)"
      ],
      "metadata": {
        "id": "EQiTJwj_a2FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ordenarlos por distancia y mostrar con drawMatches los mejores\n",
        "\n",
        "ej. matches[:10]."
      ],
      "metadata": {
        "id": "9Pc2tvACb8o_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matches = sorted(matches, key=lambda x: x.distance)"
      ],
      "metadata": {
        "id": "4J29547nb7d4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = 0\n",
        "print(\"Hay \",len(matches), \"matches\")\n",
        "print(\"El match \", corr, \" está conformado por los keyponts -> kpts1: \", matches[corr].queryIdx, \" y \", matches[corr].trainIdx )\n",
        "print(\"El keypoint \", matches[corr].queryIdx, \" de la imagen 1 con coordenadas Kpts1: \", kpts1[matches[corr].queryIdx].pt)\n",
        "print(\"corresponde al keypoint \", matches[corr].trainIdx, \" de la imagen 2 con coordenadas Kpts2: \", kpts2[matches[corr].trainIdx].pt)"
      ],
      "metadata": {
        "id": "3J_S7U7mdk_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desplegar resultados"
      ],
      "metadata": {
        "id": "gMRXdiBscJml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "I3 = cv2.drawMatches(I1, kpts1, I2, kpts2, matches[:20], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
        "cv2_imshow(I3)"
      ],
      "metadata": {
        "id": "qgFnoLubcKkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 2: Imagen panorámica"
      ],
      "metadata": {
        "id": "kMgZ8o_tjcU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imutils import paths\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4H6F7av0kfsG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Función para mostrar las imágenes"
      ],
      "metadata": {
        "id": "xXRBHRextwIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(*imgs, figsize=(10,5), hide_ticks=False):\n",
        "    '''Display one or multiple images.'''\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    width = np.ceil(np.sqrt(len(imgs))).astype('int')\n",
        "    height = np.ceil(len(imgs) / width).astype('int')\n",
        "    for i, img in enumerate(imgs, 1):\n",
        "        ax = f.add_subplot(height, width, i)\n",
        "        if hide_ticks:\n",
        "            ax.axis('off')\n",
        "        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "xxXABxH4qRNU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicialización"
      ],
      "metadata": {
        "id": "mWWO9G1QtzHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagePaths = sorted(list(paths.list_images(\"./\")))\n",
        "images = []\n",
        "images_gray = []\n",
        "kpts = []\n",
        "desc = []\n",
        "\n",
        "akaze = cv2.AKAZE_create()\n",
        "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)"
      ],
      "metadata": {
        "id": "-RxxSizGqVgd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for imagePath in imagePaths:\n",
        "    image = cv2.imread(imagePath)\n",
        "\n",
        "    scale_percent = 20  # Reducir a este porcentaje\n",
        "    width = int(image.shape[1] * scale_percent / 100)\n",
        "    height = int(image.shape[0] * scale_percent / 100)\n",
        "    image = cv2.resize(image, (width, height), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    images.append(image)\n",
        "\n",
        "    keypoints, features = akaze.detectAndCompute(image, None)\n",
        "    kpts.append(keypoints)\n",
        "    desc.append(features)\n",
        "plot_images(images[0], images[1])"
      ],
      "metadata": {
        "id": "_5hRQoXxqZNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matches = bf.match(desc[0], desc[1])\n",
        "matches = sorted(matches, key=lambda x: x.distance)\n",
        "\n",
        "keypoints_drawn_left = cv2.drawKeypoints(images[0], kpts[0], None, color=(0, 0, 255))\n",
        "keypoints_drawn_right = cv2.drawKeypoints(images[1], kpts[1], None, color=(0, 0, 255))\n",
        "\n",
        "plot_images(images[0], keypoints_drawn_left, images[1], keypoints_drawn_right)"
      ],
      "metadata": {
        "id": "tdLoMAyHqndJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matches_drawn = cv2.drawMatches(images[0], kpts[0], images[1], kpts[1], matches[:100], None, matchColor=(0,0,255), flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
        "plot_images(matches_drawn)"
      ],
      "metadata": {
        "id": "C6TiccG5qq9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "left_pts = []\n",
        "right_pts = []\n",
        "for m in matches[:100]:\n",
        "    l = kpts[0][m.queryIdx].pt\n",
        "    r = kpts[1][m.trainIdx].pt\n",
        "    left_pts.append(l)\n",
        "    right_pts.append(r)"
      ],
      "metadata": {
        "id": "slKRKSxaqvft"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M, _ = cv2.findHomography(np.float32(right_pts), np.float32(left_pts))\n",
        "dim_x = images[0].shape[1] + images[1].shape[1]\n",
        "dim_y = max(images[0].shape[0]+100, images[1].shape[0]+100)\n",
        "dim = (dim_x, dim_y)"
      ],
      "metadata": {
        "id": "ux6BzSzJqyV2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warped = cv2.warpPerspective(images[1], M, dim)\n",
        "plot_images(warped)\n",
        "comb = warped.copy()\n",
        "# combinar las dos imagenes\n",
        "comb[0:images[0].shape[0],0:images[0].shape[1]] = images[0]\n",
        "# crop\n",
        "r_crop = 1300\n",
        "comb = comb[:, :r_crop]\n",
        "plot_images(comb)"
      ],
      "metadata": {
        "id": "b2Nmkirtq1c8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}