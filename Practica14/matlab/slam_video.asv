%% Inicialización del mapa
vidObj = VideoReader('videotest.mp4');
vidObj.CurrentTime = 10;

% Tomar la primer imagen
currFrameIdx = 1;
currI = readFrame(vidObj);
pause(1/vidObj.FrameRate);
himage = imshow(currI);

% Calibrar cámara (En este ejemplo: Logitech c920)
% cameraParams <- resultado de aplicar herramienta cameraCalibrator
% De preferencia rectificar imágenes:
% currI = undistort(currI, cameraParams)
%focalLength    = [643.5, 642.7];     %c920
%principalPoint = [313.1, 234.9];     %c920
%focalLength    = [485.9, 485.6];    
%principalPoint = [321.3, 238.8]; 
focalLength    = [1202, 1202];    
principalPoint = [640, 360]; 
imageSize      = size(currI,[1 2]);  
intrinsics     = cameraIntrinsics(focalLength, principalPoint, imageSize);

% Detect and extract ORB features
% Importante: Asumimos imágenes rectificadas, si no es así, modificar:
% [preFeatures, prePoints] = helperDetectAndExtractFeatures(currI, 
% scaleFactor, numLevels, numPoints, intrinsics);
scaleFactor = 1.2;
numLevels   = 8;
numPoints   = 1000;
[preFeatures, prePoints] = helperDetectAndExtractFeatures(currI, scaleFactor, numLevels, numPoints); 
preFeatures = preFeatures(1:ceil(end/2),:)

currFrameIdx = currFrameIdx + 1;
firstI       = currI; % Guardar frame actual

isMapInitialized  = false;

% inicialización del mapa
% le damos un un rango de 100 imágenes
% si en esos 100 frames no hay movimiento no será posible inicializar
while ~isMapInitialized && currFrameIdx < 100
    currI = readFrame(vidObj);
    pause(1/vidObj.FrameRate);
    % De nuevo se asume rectificada
    [currFeatures, currPoints] = helperDetectAndExtractFeatures(currI, scaleFactor, numLevels, numPoints); 
    
    currFrameIdx = currFrameIdx + 1;
    
    % feature match
    indexPairs = matchFeatures(preFeatures, currFeatures, 'Unique', true, ...
        'MaxRatio', 0.9, 'MatchThreshold', 40);
    
    preMatchedPoints  = prePoints(indexPairs(:,1),:);
    currMatchedPoints = currPoints(indexPairs(:,2),:);

    % Si no hay suficientes matches, revisar el siguiente frame
    minMatches = 100;
    if size(indexPairs, 1) < minMatches
        continue
    end
    
    % Calcular homografía y evaluar reconstrucción
    [tformH, scoreH, inliersIdxH] = helperComputeHomography(preMatchedPoints, currMatchedPoints);

    % Calcular matriz fundamental y evaluar recontrucción
    [tformF, scoreF, inliersIdxF] = helperComputeFundamentalMatrix(preMatchedPoints, currMatchedPoints);
    
    % Seleccionar modelo heurísticamente
    ratio = scoreH/(scoreH + scoreF);
    ratioThreshold = 0.45;
    if ratio > ratioThreshold
        inlierTformIdx = inliersIdxH;
        tform          = tformH;
    else
        inlierTformIdx = inliersIdxF;
        tform          = tformF;
    end

    % Calcular ubicación cámara a escala
    % Se pueden usar mitad de los puntos para reducir cómputo
    inlierPrePoints  = preMatchedPoints(inlierTformIdx);
    inlierCurrPoints = currMatchedPoints(inlierTformIdx);
    [relOrient, relLoc, validFraction] = relativeCameraPose(tform, intrinsics, ...
        inlierPrePoints(1:1:end), inlierCurrPoints(1:1:end));
    
    % Si no hay suficientes inliers, pasar al siguiente frame
    if validFraction < 0.9 || numel(size(relOrient))==3
        continue
    end
    
    % Triangular 2 vistas para obtener puntos 3D
    relPose = rigid3d(relOrient, relLoc);
    minParallax = 1; % grados
    [isValid, xyzWorldPoints, inlierTriangulationIdx] = helperTriangulateTwoFrames(...
        rigid3d, relPose, inlierPrePoints, inlierCurrPoints, intrinsics, minParallax);
    
    if ~isValid
        continue
    end
    
    % Obtener indices originales de los features en los dos keyframes
    indexPairs = indexPairs(inlierTformIdx(inlierTriangulationIdx),:);
    
    isMapInitialized = true;
    
    disp(['Mapa inicializado con los frames 1 y ', num2str(currFrameIdx-1)])
end % Fin de la inicialización del mapa

if isMapInitialized
    close(himage.Parent.Parent); % Cerrar ventana
    % mostrar matches
    hfeature = showMatchedFeatures(firstI, currI, prePoints(indexPairs(:,1)), ...
        currPoints(indexPairs(:, 2)), 'Montage');
else
    error('No se pudo inicializar el mapa.')
end

%% Guardar Keyframes y puntos del mapa iniciales
% Crear un objeto imageviewset vacío para guardar los keyframes
vSetKeyFrames = imageviewset;

% Crear un objeto worldpointset vacío para guardar los puntos 3D
mapPointSet   = worldpointset;

% Crear un objeto helperViewDirectionAndDepth para guardar puntos de vista y profundidad 
directionAndDepth = helperViewDirectionAndDepth(size(xyzWorldPoints, 1));

% Añadir el primer Keyframe. 
% Colocar camara asociada al primer keyframe en el origen
preViewId     = 1;
vSetKeyFrames = addView(vSetKeyFrames, preViewId, rigid3d, 'Points', prePoints,...
    'Features', preFeatures.Features);

% Añadir segundo frame
currViewId    = 2;
vSetKeyFrames = addView(vSetKeyFrames, currViewId, relPose, 'Points', currPoints,...
    'Features', currFeatures.Features);

% Conectar primer y segundo frame
vSetKeyFrames = addConnection(vSetKeyFrames, preViewId, currViewId, relPose, 'Matches', indexPairs);

% Agragr puntos 3D
[mapPointSet, newPointIdx] = addWorldPoints(mapPointSet, xyzWorldPoints);

% Agregar observaciones de los puntos
preLocations  = prePoints.Location;
currLocations = currPoints.Location;
preScales     = prePoints.Scale;
currScales    = currPoints.Scale;

% Agregar los puntos de la imagen correspondientes a los puntos del mapa en
% el primer frame
mapPointSet   = addCorrespondences(mapPointSet, preViewId, newPointIdx, indexPairs(:,1));

% Agregar los puntos de la imagen correspondientes a los puntos del mapa en
% el segundo frame
mapPointSet   = addCorrespondences(mapPointSet, currViewId, newPointIdx, indexPairs(:,2));

% ---------- Inicializar reconocimiento ------------%

% Cargar el bag of features
bofData         = load('bagOfFeaturesData.mat');

% Inicializar el reconocimiento
loopDatabase    = invertedImageIndex(bofData.bof,"SaveFeatureLocations", false);

% Agregar features del primero y segundo frame a la base de datos
addImageFeatures(loopDatabase, preFeatures, preViewId);
addImageFeatures(loopDatabase, currFeatures, currViewId);

%----------- Ajustar la reconstruccion inicial -----------%

% bundle adjustment en los primeros dos frames
tracks       = findTracks(vSetKeyFrames);
cameraPoses  = poses(vSetKeyFrames);

[refinedPoints, refinedAbsPoses] = bundleAdjustment(xyzWorldPoints, tracks, ...
    cameraPoses, intrinsics, 'FixedViewIDs', 1, ...
    'PointsUndistorted', true, 'AbsoluteTolerance', 1e-7,...
    'RelativeTolerance', 1e-15, 'MaxIteration', 20, ...
    'Solver', 'preconditioned-conjugate-gradient');

% Escalar mapa y pose de la cámara usando la profundidad media de los
% puntos del mapa
medianDepth   = median(vecnorm(refinedPoints.'));
refinedPoints = refinedPoints / medianDepth;

refinedAbsPoses.AbsolutePose(currViewId).Translation = ...
    refinedAbsPoses.AbsolutePose(currViewId).Translation / medianDepth;
relPose.Translation = relPose.Translation/medianDepth;

% Actualizar kyframes
vSetKeyFrames = updateView(vSetKeyFrames, refinedAbsPoses);
vSetKeyFrames = updateConnection(vSetKeyFrames, preViewId, currViewId, relPose);

% Actualizar puntos del mapa
mapPointSet   = updateWorldPoints(mapPointSet, newPointIdx, refinedPoints);

% Actualizar la vista y profundidad
directionAndDepth = update(directionAndDepth, mapPointSet, vSetKeyFrames.Views, newPointIdx, true);

% Visualizar los matches en el frame actual
close(hfeature.Parent.Parent);
featurePlot   = helperVisualizeMatchedFeatures(currI, currPoints(indexPairs(:,2)));

% Visualizar puntos iniciales y trayectoria de la cámara
mapPlot       = helperVisualizeMotionAndStructure(vSetKeyFrames, mapPointSet);
showLegend(mapPlot);

%% Tracking

% ViewId del frame actual
currKeyFrameId   = currViewId;

% ViewId del último frame
lastKeyFrameId   = currViewId;

% ViewId del keyframe de referencia con más puntos del mapa visibles
refKeyFrameId    = currViewId;

% Índice del último keyframe 
lastKeyFrameIdx  = currFrameIdx - 1; 

% Índice de todos los keyframes
addedFramesIdx   = [1; lastKeyFrameIdx];

isLoopClosed     = false;

%------------ Main loop-------------------%

while ~isLoopClosed && currFrameIdx < 1000
    currI = readFrame(vidObj);
    pause(1/vidObj.FrameRate);
    [currFeatures, currPoints] = helperDetectAndExtractFeatures(currI, scaleFactor, numLevels, numPoints);

    % Track último keyframe
    % mapPointsIdx:   Indices de los puntos del mapa observados en el frame actual
    % featureIdx:     Indices de sus correspondientes features en el frame actual 
    [currPose, mapPointsIdx, featureIdx] = helperTrackLastKeyFrame(mapPointSet, ...
        vSetKeyFrames.Views, currFeatures, currPoints, lastKeyFrameId, intrinsics, scaleFactor);
    
    % Track mapa local
    % refKeyFrameId:      ViewId  del keyframe de referencia 
    % localKeyFrameIds:   ViewId de los keyframes que conectan con el
    %                       keyframe de referencia
    while isempty(mapPointsIdx)
        currI = readFrame(vidObj);
        [currFeatures, currPoints] = helperDetectAndExtractFeatures(currI, scaleFactor, numLevels, numPoints);
    end

    [refKeyFrameId, localKeyFrameIds, currPose, mapPointsIdx, featureIdx] = ...
        helperTrackLocalMap(mapPointSet, directionAndDepth, vSetKeyFrames, mapPointsIdx, ...
        featureIdx, currPose, currFeatures, currPoints, intrinsics, scaleFactor, numLevels);
   
    % Checar si el frame actual es un keyframe.
    % Un keyframe es un frame que cumple con:
    %
    % 1. Al menos 20 frames han pasado desde el último keyframe o el frame
    % actual tiene menos de 100 puntos en el mapa.
    % 2. Los puntos del mapa que trackeados en el frame actual son menos
    % del 90% de los puntos trackeados por el keyframe de referencia.
    numSkipFrames = 10;
    isKeyFrame = helperIsKeyFrame(mapPointSet, refKeyFrameId, lastKeyFrameIdx, ...
        currFrameIdx, mapPointsIdx, numSkipFrames);
    
    % Desplegar matches
    updatePlot(featurePlot, currI, currPoints(featureIdx));
    
    if ~isKeyFrame
        currFrameIdx = currFrameIdx + 1;
        continue
    end
    
    % Actualizar ID del frame actual 
    currKeyFrameId  = currKeyFrameId + 1;

    % ------------ Mapeo Local -------------%
    % Añadir el nuevo keyframe 
    [mapPointSet, vSetKeyFrames] = helperAddNewKeyFrame(mapPointSet, vSetKeyFrames, ...
        currPose, currFeatures, currPoints, mapPointsIdx, featureIdx, localKeyFrameIds);
    
    % Eliminar outliers del mapa de puntos que son observados
    % en menos de 3 keyframes
    [mapPointSet, directionAndDepth, mapPointsIdx] = helperCullRecentMapPoints(mapPointSet, ...
        directionAndDepth, mapPointsIdx, newPointIdx);
    
    % Crear un nuevo mapa por triangulación
    minNumMatches = 20;
    minParallax   = 3;
    [mapPointSet, vSetKeyFrames, newPointIdx] = helperCreateNewMapPoints(mapPointSet, vSetKeyFrames, ...
        currKeyFrameId, intrinsics, scaleFactor, minNumMatches, minParallax);
    
    % Actualizar vista y profundidad
    directionAndDepth = update(directionAndDepth, mapPointSet, vSetKeyFrames.Views, ...
        [mapPointsIdx; newPointIdx], true);
    
    % bundle adjustment local
    [mapPointSet, directionAndDepth, vSetKeyFrames, newPointIdx] = helperLocalBundleAdjustment( ...
        mapPointSet, directionAndDepth, vSetKeyFrames, ...
        currKeyFrameId, intrinsics, newPointIdx); 
    
    % desplegar puntos 3D y trayectoria de la cámara
    updatePlot(mapPlot, vSetKeyFrames, mapPointSet);

    % ------------------- Cierre de loop ----------------%
    % Cerrar loop después de haber creado cierta cantidad de keyframes    
    if currKeyFrameId > 20
        
        % Mínimo de matches
        loopEdgeNumMatches = 50;
        
        % Detectar posible cierre de circuito entre los keyframes candidatos
        [isDetected, validLoopCandidates] = helperCheckLoopClosure(vSetKeyFrames, currKeyFrameId, ...
            loopDatabase, currI, loopEdgeNumMatches);
        
        if isDetected 
            % Añadir conexiones
            [isLoopClosed, mapPointSet, vSetKeyFrames] = helperAddLoopConnections(...
                mapPointSet, vSetKeyFrames, validLoopCandidates, currKeyFrameId, ...
                currFeatures, currPoints, loopEdgeNumMatches);
        end
    end
    
    % Si no se detecta el cierre del circuito
    % añadir los features actuales a la base de datos
    if ~isLoopClosed
        addImageFeatures(loopDatabase,  currFeatures, currKeyFrameId);
    end
    
    % Actualizar IDs e índices
    lastKeyFrameId  = currKeyFrameId;
    lastKeyFrameIdx = currFrameIdx;
    addedFramesIdx  = [addedFramesIdx; currFrameIdx]; %#ok<AGROW>
    currFrameIdx    = currFrameIdx + 1;
end % End of main loop
 
%% Optimize the poses
minNumMatches      = 30;
[vSetKeyFramesOptim, poseScales] = optimizePoses(vSetKeyFrames, minNumMatches, 'Tolerance', 1e-16);

% Update map points after optimizing the poses
mapPointSet = helperUpdateGlobalMap(mapPointSet, directionAndDepth, ...
    vSetKeyFrames, vSetKeyFramesOptim, poseScales);

updatePlot(mapPlot, vSetKeyFrames, mapPointSet);

% Plot the optimized camera trajectory
optimizedPoses  = poses(vSetKeyFramesOptim);
plotOptimizedTrajectory(mapPlot, optimizedPoses)

% Update legend
showLegend(mapPlot);